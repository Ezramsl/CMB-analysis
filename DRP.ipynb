{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kr_3cwV2PDMV"
      },
      "outputs": [],
      "source": [
        "!pip install healpy\n",
        "!pip install camb\n",
        "!pip install emcee\n",
        "!pip install corner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFbxTUeXPKmZ"
      },
      "outputs": [],
      "source": [
        "import healpy as hp\n",
        "import camb\n",
        "import numpy as np\n",
        "import emcee\n",
        "import matplotlib.pyplot as plt\n",
        "import corner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-qSPTWvPwqy"
      },
      "outputs": [],
      "source": [
        "input_map = \"https://irsa.ipac.caltech.edu/data/Planck/release_2/all-sky-maps/maps/component-maps/cmb/COM_CMB_IQU-commander_1024_R2.02_full.fits\"\n",
        "cmb_map = hp.read_map(input_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SveiAHJMP2EC"
      },
      "outputs": [],
      "source": [
        "lmax = 2500  # Maximum multipole to consider\n",
        "cl = hp.anafast(cmb_map, lmax=lmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzHA_5F6P7Ha"
      },
      "outputs": [],
      "source": [
        "def get_theoretical_spectrum(params, lmax):\n",
        "    H0, ombh2, omch2, As, ns, tau = params\n",
        "    pars = camb.CAMBparams()\n",
        "    pars.set_cosmology(H0=H0, ombh2=ombh2, omch2=omch2, mnu=0.06, omk=0, tau=tau)\n",
        "    pars.InitPower.set_params(As=As, ns=ns, r=0)\n",
        "    pars.set_for_lmax(lmax, lens_potential_accuracy=0)\n",
        "\n",
        "    results = camb.get_results(pars)\n",
        "    powers = results.get_cmb_power_spectra(pars, CMB_unit=\"muK\")\n",
        "    return powers[\"total\"][0:(lmax+1), 0]  # Start from l=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FSqUqUJRBbS"
      },
      "outputs": [],
      "source": [
        "def ln_likelihood(params, cl_data, lmax):\n",
        "    cl_theory = get_theoretical_spectrum(params, lmax)\n",
        "\n",
        "    # Check for NaN or infinite values in the power spectrum\n",
        "    if np.any(np.isnan(cl_theory)) or np.any(np.isinf(cl_theory)):\n",
        "        return -np.inf\n",
        "\n",
        "    epsilon = 1e-12\n",
        "    diff = cl_data - cl_theory\n",
        "    chi2 = np.sum(diff**2 / (cl_theory + epsilon))\n",
        "    return -0.5 * chi2\n",
        "\n",
        "def ln_prior(params):\n",
        "    H0, ombh2, omch2, As, ns, tau = params\n",
        "\n",
        "    # Check if any of the parameters are NaN or infinite\n",
        "    if np.any(np.isnan(params)) or np.any(np.isinf(params)):\n",
        "        return -np.inf\n",
        "\n",
        "    # Update the bounds for the parameters if necessary\n",
        "    if 40 < H0 < 100 and 0.005 < ombh2 < 0.1 and 0.01 < omch2 < 0.9 and 1e-10 < As < 1e-8 and 0.8 < ns < 1.2 and 0.01 < tau < 0.2:\n",
        "        return 0.0\n",
        "    return -np.inf\n",
        "\n",
        "def ln_posterior(params, cl_data, lmax):\n",
        "    lp = ln_prior(params)\n",
        "    if not np.isfinite(lp):\n",
        "        return -np.inf\n",
        "    return lp + ln_likelihood(params, cl_data, lmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEv1FVTxRFB6"
      },
      "outputs": [],
      "source": [
        "nwalkers = 100000\n",
        "ndim = 6\n",
        "nsteps = 100\n",
        "\n",
        "initial_params = np.array([70, 0.022, 0.12, 2.1e-9, 0.96, 0.06])\n",
        "noise_scale = 5  # Set the noise scale factor\n",
        "#initial_params_scale = np.array([5, 0.1, 0.8, 1e-8, 0.3, 0.15])\n",
        "#initial_params_scale = noise_scale * initial_params\n",
        "pos = initial_params + noise_scale * np.random.randn(nwalkers, ndim)\n",
        "\n",
        "sampler = emcee.EnsembleSampler(nwalkers, ndim, ln_posterior, args=(cl, lmax));\n",
        "sampler.run_mcmc(pos, nsteps, progress=True);\n",
        "print('\\nDone')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLgFIBzwRXxZ"
      },
      "outputs": [],
      "source": [
        "# Discard burn-in samples and flatten the chain\n",
        "burn_in = 90\n",
        "samples = sampler.get_chain(discard=burn_in, flat=True)\n",
        "\n",
        "# Extract H_0 samples\n",
        "H0_samples = samples[:, 0]\n",
        "\n",
        "# Calculate the mean and 1-sigma confidence intervals\n",
        "H0_mean = np.mean(H0_samples)\n",
        "H0_std = np.std(H0_samples)\n",
        "H0_lower = H0_mean - H0_std\n",
        "H0_upper = H0_mean + H0_std\n",
        "\n",
        "print(f\"H_0 = {H0_mean:.2f} + {H0_upper - H0_mean:.2f} - {H0_mean - H0_lower:.2f} km/s/Mpc\")\n",
        "\n",
        "# Plot the posterior distributions for all parameters\n",
        "labels = [\"H_0\", \"Ω_b h^2\", \"Ω_c h^2\", \"A_s\", \"n_s\", \"τ\"]\n",
        "corner.corner(samples, labels=labels, show_titles=True)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}